{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing...\n",
      "C:\\Users\\tjvan\\Documents\\local_programs\\miniconda3\\envs\\pyds\\python.exe\n",
      "3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]\n",
      "C:\\Users\\tjvan\\Documents\\projects_for_learning\\01_pynumdraw\\pynumdraw\\back_end\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # This will be the file that is converted to a .py and deployed to server\n",
    "\n",
    "\n",
    "print(\"importing...\")\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(os.getcwd())\n",
    "\n",
    "MODEL_SEMVER = '0.2.0'\n",
    "IS_TEST_RUN = False # gross, I know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_resize_image(p_image_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    expect a one-dimensional list of pixel values that make up a single-channel 300x300 pixel image.\n",
    "    The pixels are in row-wise order. \n",
    "    \n",
    "    #expected_pixel_width = 300\n",
    "    #expected_pixel_height = 300\n",
    "    #model_required_pixel_width = 28\n",
    "    #model_required_pixel_height = 28\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # determine new shape (28x28 if executing back-end test; 300x300 if coming from front-end)\n",
    "    print(\"len(p_image_data) in reshape_and_resize_image function\", len(p_image_data))\n",
    "    \n",
    "    width_and_height = int(math.sqrt(len(p_image_data)))\n",
    "    print(f\"dimensions of front end canvas must be {width_and_height} by {width_and_height}\")\n",
    "    \n",
    "    if len(p_image_data) == (28 * 28):\n",
    "        print(\"yes\")\n",
    "        # convert to new shape\n",
    "        x = np.asarray(p_image_data)\n",
    "        x = x.reshape((1, 28, 28, 1))\n",
    "    \n",
    "    elif len(p_image_data) == (width_and_height * width_and_height):\n",
    "        print(\"no\")\n",
    "        # resize and convert to new shape\n",
    "        x = np.asarray(p_image_data)\n",
    "        x = x.reshape((width_and_height, width_and_height))\n",
    "        x = resize(x, output_shape=(28, 28, 1))\n",
    "        x = x.reshape((1, 28, 28, 1))\n",
    "    else:\n",
    "        raise(\"Error: Looks like front-end sent us a non-square canvas...\")\n",
    "    \n",
    "    print(\"shape of prediction after `reshape_and_resize_image()` function:\", x.shape)\n",
    "    return x\n",
    "\n",
    "\n",
    "def flatten_ndarray_to_1d_list(p_ndarray):\n",
    "    \"\"\"\n",
    "    given ndarray of dimensions (width, height, channel), flatten those dimensions into\n",
    "    a single dimension list. This is mostly a helper function to create sample test\n",
    "    data that closely mimics what we would receive from the javascript front-end AJAX\n",
    "    call after the user has drawn their number.\n",
    "    \"\"\"\n",
    "    x = list(chain.from_iterable(p_ndarray.tolist()))\n",
    "    print(\"length of returned list from flatten_ndarray_to_1d_list:\", len(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "def predict_on_new_data(p_newdata, p_model, p_model_version, p_label=None):\n",
    "    \"\"\"\n",
    "    p_newdata (1d flat list of row-wise datapoints with length of 28 * 28)\n",
    "    \n",
    "    returns a dict with keys:\n",
    "    - predicted_number (int): the number the model predicts was drawn on the canvas\n",
    "    - confidence (str): how confident the model is about the prediction\n",
    "    - model_version (str): the semantic version of the model used for the prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # set up class labels\n",
    "    # class_labels = [str(x) for x in range(0, 10)]\n",
    "    \n",
    "    # preprocess and generate prediction class probabilities\n",
    "    p_newdata = reshape_and_resize_image(p_newdata)\n",
    "    predicted_probabilities = p_model.predict(p_newdata)\n",
    "    \n",
    "    # collect results\n",
    "    results = {} \n",
    "    results[\"predicted_number\"] = int(np.argmax(predicted_probabilities))\n",
    "    results[\"confidence\"] =  str(int(100 * np.max(predicted_probabilities)))\n",
    "    results[\"model_version\"] = str(p_model_version)\n",
    "    if p_label:\n",
    "        results[\"label\"] = p_label\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tensorflow model weights...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load model immediately\n",
    "print(\"loading tensorflow model weights...\")\n",
    "model = keras.models.load_model(filepath=f\"pynumdraw_model_{MODEL_SEMVER}.hdf5\", compile=False)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/predict_number/', methods=['POST'])\n",
    "def predict_number():\n",
    "    print(\"in predict_number function now\")\n",
    "    data = request.json\n",
    "    results = predict_on_new_data(data['new_data'], model, MODEL_SEMVER)\n",
    "    \n",
    "    return jsonify(results)\n",
    "\n",
    "@app.route(\"/hello/\")\n",
    "def hello():\n",
    "    print(\"in hello function now\")\n",
    "    return \"hello_world\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of returned list from flatten_ndarray_to_1d_list: 784\n",
      "len(p_image_data) in reshape_and_resize_image function 784\n",
      "yes\n",
      "shape of prediction after `reshape_and_resize_image()` function: (1, 28, 28, 1)\n",
      "{'predicted_number': 9, 'confidence': '100', 'model_version': '0.2.0', 'label': 9}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADmxJREFUeJzt3X2MXOV1x/Hf8XZtg40DW2PjgomBQIJxUlO2dhGUUlm8JZEMqUJDEuREiKUKjuoURUEoamjaqlZFSEmTRlriDSblLVWgWKnVGjlRCQmyvCYUbBwMONtk440X1w42NCz7cvrHXlcbs/PM7Nw7c2d9vh8Jzcw99+Uw8m/v7D5z72PuLgDxzCi7AQDlIPxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4L6rWYebKbN8tma08xDAqG8qTf0lg9ZLevmCr+ZXS3pHkltkr7h7utT68/WHK20VXkOCSBhm2+ted26P/abWZukr0m6RtJSSTeY2dJ69wegufL8zr9C0svuvtfd35L0sKTVxbQFoNHyhP90ST+f8Lo/W/YbzKzLzHrNrHdYQzkOB6BIecI/2R8V3nZ9sLt3u3unu3e2a1aOwwEoUp7w90taPOH1GZL25WsHQLPkCf92Seea2VlmNlPSRyRtKqYtAI1W91Cfu4+Y2VpJ/6Hxob4ed99VWGcAGirXOL+7b5a0uaBeADQRX+8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqFyz9JpZn6QjkkYljbh7ZxFNAWi8XOHP/LG7HyhgPwCaiI/9QFB5w++StpjZDjPrKqIhAM2R92P/Je6+z8wWSHrCzH7i7k9OXCH7odAlSbN1Ys7DAShKrjO/u+/LHgclPSZpxSTrdLt7p7t3tmtWnsMBKFDd4TezOWZ20tHnkq6UtLOoxgA0Vp6P/QslPWZmR/fzoLv/eyFdAWi4usPv7nsl/W6BvcQ1oy1Ztgvfk6y/cv28irUffvSu5LYL2uYk69UMjLyerF/24Gcr1t71188ltx174426ekJtGOoDgiL8QFCEHwiK8ANBEX4gKMIPBFXEVX2oYuia30/W7S8Gk/UtS+/PcfTZyeqwj+bYtzS/7YRk/YUbv1qxdsGSTya3PfvjLyTrPjKSrCONMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4fxHG72lQ0Zl/+WKyvuHM7xfZzZQM+XCyPuxjyfrcGfXfnWnXH34zWV/+2U8n62f83Y/qPjY48wNhEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzz1yoxlv/KXSuTm373zK/lOvSB0V8n6/98uPId1Hv+5arktu/c9Fqy7j/elaz/9OH3JevVxvJTLvhA+vsRr9/728n66IH/qfvYEXDmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgzN3TK5j1SPqgpEF3X5Yt65D0iKQlkvokXe/uh6odbJ51+EpblbPlcsyYXfn+95te+WGufVe7pv69/5a+rv28W7bnOn4ebaeemqzf+vQPKtauPCHfFNzLvrk2WV/y+adz7X862uZbddgPpm8wkanlzH+fpKuPWXa7pK3ufq6krdlrANNI1fC7+5OSDh6zeLWkjdnzjZKuLbgvAA1W7+/8C919QJKyxwXFtQSgGRr+3X4z65LUJUmzdWKjDwegRvWe+feb2SJJyh4rzjTp7t3u3unune2q/2aPAIpVb/g3SVqTPV8j6fFi2gHQLFXDb2YPSXpa0rvNrN/MbpK0XtIVZvaSpCuy1wCmkarj/EVinH9y523+s3T95vLG8fP61Y0XV6w9tf6rufb90JGFyfoj77+0Ym1kb1+uY7eqosf5ARyHCD8QFOEHgiL8QFCEHwiK8ANBcevuGv3qQ8sT1fRQ357ht5L1pX/zy2R9JFktV9v89O2zP/P5hxt27BtO2p+s/9UXT6lYe9fH+wruZvrhzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOX6ND76npKslJvelt6RXGmndZ9VS1XfDuZH3Rhl8k638y90CR7UzJhos3Vqytb+9MbutVvptxPODMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc5fo4XbRysXb0pv+76Z6XH+F9edkayfc1t/+gApM9LHtouWJuuHvvi/yfrji/9zyi01y6d+/NGKtcUju5rYSWvizA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVUd5zezHkkflDTo7suyZXdKulnSq9lqd7j75kY12QpOfOK5hu37U1dtSdY39l+drHe8UPna8/03v5nc9r8uvi9Zb2U/HUn/v73j0bmVi02cmr5V1XLmv0/SZP/6vuzuy7P/juvgA8ejquF39yclHWxCLwCaKM/v/GvN7Dkz6zGzyvMiAWhJ9Yb/65LOkbRc0oCkL1Va0cy6zKzXzHqHNVTn4QAUra7wu/t+dx919zFJ90pakVi329073b2zXbPq7RNAweoKv5ktmvDyOkk7i2kHQLPUMtT3kKTLJc03s35JX5B0uZktl+SS+iTd0sAeATSAeRPHO+dZh6+0VU07XqES18W/9JX0PeBfvO6fiu5m2uh+bUnFWtc7+nLt+8a+K5L1Q5fEG6Ta5lt12A/WNMkE3/ADgiL8QFCEHwiK8ANBEX4gKMIPBMWtu2s1VvnW3eet25Hc9KK9n07WT75qIFl/5PxvJevz206oWBvTWHLb3qH0rb2/MfhHyfrgn56crB++6Hcq1rr+Md8Q6J5vpacPP1VP59r/8Y4zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/AXxkJFlfdPeP0ju4O13+2JXrkvXXzmqvWJsxnN53R0+1sfAjuerzxipfMv7YGx3Jbc9pfzVZP+17g8l6YlJ1iDM/EBbhB4Ii/EBQhB8IivADQRF+ICjCDwTFOP800L6lN1mf36Q+6tJW+fwy09Ij8b8cnZesj+55pa6WMI4zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXWc38wWS7pf0mmSxiR1u/s9ZtYh6RFJSyT1Sbre3Q81rlVMRwcvrnzf/g+c+Fpy26UPrE3Wz+a+/LnUcuYfkXSbu58v6Q8k3WpmSyXdLmmru58raWv2GsA0UTX87j7g7s9kz49I2i3pdEmrJW3MVtso6dpGNQmgeFP6nd/Mlki6UNI2SQvdfUAa/wEhaUHRzQFonJrDb2ZzJX1H0jp3PzyF7brMrNfMeoc1VE+PABqgpvCbWbvGg/+Auz+aLd5vZouy+iJJk95N0d273b3T3TvbNauIngEUoGr4zcwkbZC0290n3md2k6Q12fM1kh4vvj0AjVLLJb2XSLpR0vNm9my27A5J6yV928xukvQzSR9uTIuYzkY+drDubS+9bGeyvq/uPUOqIfzu/pQkq1BeVWw7AJqFb/gBQRF+ICjCDwRF+IGgCD8QFOEHguLW3WhZnzntiWT9c8s+kayP7fxJgd0cfzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPOjZZ3f3p6sH1hxSrLekb4dQHic+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoqtfzm9liSfdLOk3SmKRud7/HzO6UdLOkV7NV73D3zY1qFNPT0PfmV6ztWJredmHbr5P1k/ek60ir5WYeI5Juc/dnzOwkSTvM7OhsCl9297sa1x6ARqkafncfkDSQPT9iZrslnd7oxgA01pR+5zezJZIulLQtW7TWzJ4zsx4zm/SeSmbWZWa9ZtY7rKFczQIoTs3hN7O5kr4jaZ27H5b0dUnnSFqu8U8GX5psO3fvdvdOd+9s16wCWgZQhJrCb2btGg/+A+7+qCS5+353H3X3MUn3SlrRuDYBFK1q+M3MJG2QtNvd756wfNGE1a6TxL1SgWnE3D29gtmlkn4g6XmND/VJ0h2SbtD4R36X1CfpluyPgxXNsw5faatytgygkm2+VYf9oNWybi1/7X9K0mQ7Y0wfmMb4hh8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoqtfzF3ows1cl/feERfMlHWhaA1PTqr21al8SvdWryN7e6e6n1rJiU8P/toOb9bp7Z2kNJLRqb63al0Rv9SqrNz72A0ERfiCossPfXfLxU1q1t1btS6K3epXSW6m/8wMoT9lnfgAlKSX8Zna1mb1oZi+b2e1l9FCJmfWZ2fNm9qyZ9ZbcS4+ZDZrZzgnLOszsCTN7KXucdJq0knq708x+kb13z5rZ+0vqbbGZfd/MdpvZLjP782x5qe9doq9S3remf+w3szZJeyRdIalf0nZJN7j7C01tpAIz65PU6e6ljwmb2WWSXpd0v7svy5b9vaSD7r4++8F5irt/rkV6u1PS62XP3JxNKLNo4szSkq6V9AmV+N4l+rpeJbxvZZz5V0h62d33uvtbkh6WtLqEPlqeuz8p6eAxi1dL2pg936jxfzxNV6G3luDuA+7+TPb8iKSjM0uX+t4l+ipFGeE/XdLPJ7zuV2tN+e2StpjZDjPrKruZSSw8OjNS9rig5H6OVXXm5mY6Zmbplnnv6pnxumhlhH+y2X9aacjhEnf/PUnXSLo1+3iL2tQ0c3OzTDKzdEuod8bropUR/n5Jiye8PkPSvhL6mJS778seByU9ptabfXj/0UlSs8fBkvv5f600c/NkM0urBd67Vprxuozwb5d0rpmdZWYzJX1E0qYS+ngbM5uT/SFGZjZH0pVqvdmHN0lakz1fI+nxEnv5Da0yc3OlmaVV8nvXajNel/Iln2wo4x8ktUnqcfe/bXoTkzCzszV+tpfGJzF9sMzezOwhSZdr/Kqv/ZK+IOlfJX1b0pmSfibpw+7e9D+8Vejtck1x5uYG9VZpZultKvG9K3LG60L64Rt+QEx8ww8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/B+GQFLYVClkoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IS_TEST_RUN:\n",
    "    \n",
    "    def read_mnist_image_data(image_data_file):\n",
    "        \"\"\"\n",
    "        image_data_file: path to the mnist image data file on disk.\n",
    "\n",
    "        returns a dictionary with the following keys:\n",
    "        - magic_number: to be compared against the magic number for each file on MNIST website\n",
    "        - number_of_images: the number of images included in the dataset\n",
    "        - pixel_rows: the number of pixels per row per image\n",
    "        - pixel_cols: the number of pixels per column per image\n",
    "        - data: the actual image data as ndarray with shape of (number_of_images, pixel_rows, pixel_cols)\n",
    "        \"\"\"\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        with open(image_data_file, 'rb') as f:\n",
    "            _data = f.read()\n",
    "\n",
    "        results['magic_number'] = int.from_bytes(_data[0:4], 'big')\n",
    "        results['number_of_images'] = int.from_bytes(_data[4:8], 'big')\n",
    "        results['pixel_rows'] = int.from_bytes(_data[8:12], 'big')\n",
    "        results['pixel_cols'] = int.from_bytes(_data[12:16], 'big')\n",
    "\n",
    "        pixel_data = np.asarray([pixel for pixel in _data[16:]])\n",
    "        pixel_data = pixel_data.reshape(results['number_of_images'], results['pixel_rows'], results['pixel_cols'])\n",
    "        results['data'] = pixel_data\n",
    "\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def read_mnist_label_data(label_data_file):\n",
    "        \"\"\"\n",
    "        label_data_file: path to the mnist label data file on disk.\n",
    "\n",
    "        returns a dictionary with the following keys:\n",
    "        - magic_number: to be compared against the magic number for each file on MNIST website\n",
    "        - number_of_labels: the number of labels included in the dataset\n",
    "        - labels: the actual label data as ndarray (1 dimensional)\n",
    "        \"\"\"\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        with open(label_data_file, 'rb') as f:\n",
    "            _data = f.read()\n",
    "\n",
    "        results['magic_number'] = int.from_bytes(_data[0:4], 'big')\n",
    "        results['number_of_labels'] = int.from_bytes(_data[4:8], 'big')    \n",
    "        results['labels'] = np.asarray([(label / 1.0) for label in _data[8:]]).astype('int')\n",
    "\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    # TODO: replace this with a random sample within the test dataset\n",
    "    test_indx = 99\n",
    "    \n",
    "    all_images = read_mnist_image_data(\"../data/t10k-images-idx3-ubyte\")['data'] / 255.0\n",
    "    all_labels = read_mnist_label_data(\"../data/t10k-labels-idx1-ubyte\")['labels']\n",
    "    \n",
    "    test_image = all_images[test_indx, :, :]\n",
    "    test_image = flatten_ndarray_to_1d_list(test_image)\n",
    "    test_results = predict_on_new_data(test_image, model, MODEL_SEMVER, all_labels[test_indx])\n",
    "    print(test_results)  \n",
    "    \n",
    "    \n",
    "    from matplotlib.pyplot import imshow\n",
    "    imshow(all_images[test_indx, :, :])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev (gross, I know)\n",
    "\n",
    "# nvm, this doesn't really even work. If it was a small amount of JSON I had to \n",
    "# manually create in order to test the API, that'd be one thing. But this is a\n",
    "# dense 300 x 300 pixel image that has to be tested on. So instead, we should\n",
    "# take this testing offline.\n",
    "# app.run(host='0.0.0.0', 8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prod (gross, I know)\n",
    "import bjoern\n",
    "\n",
    "print(\"starting bjoern server now!\")\n",
    "bjoern.run(app, '127.0.0.1', 8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
